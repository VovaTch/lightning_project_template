# Configuration file for a deep learning model using PyTorch Lightning

# Specify the model name
model_name: "mnist_fcn"

# Loss configuration
loss:
  aggregator_type: "weighted_sum"

  # Cross-entropy loss
  ce_loss:
    type: "basic_cls"
    weight: 1.0
    base_loss: "ce"

  # Correct ratio metric
  correct_ratio_metric:
    type: "percent_correct"

# Training settings
learn:
  # Learning rate
  learning_rate: 0.001

  # L2 weight decay
  weight_decay: 0.02

  # Batch size for training
  batch_size: 128

  # Number of training epochs
  epochs: 20

  # Beta EMA (Exponential Moving Average) for model parameters
  beta_ema: 0.9999

  # Gradient clipping to prevent exploding gradients
  gradient_clip: 0.1

  # Split factor for validation set during training
  eval_split_factor: 0.05

  # Automatic Mixed Precision (AMP) for faster training (True/False)
  amp: False

  # Number of GPU devices to use
  num_devices: 0

  # Number of CPU workers for data loading
  num_workers: 4

  # Directory to save model checkpoints
  save_path: "saved/"

  # Learning rate scheduler configuration
  scheduler:
    type: "none"  # Options: "none", "step", "cosine", etc.
    loss_monitor: "step"
    interval: "training_total_loss"
    frequency: 1

# Model architecture settings
model_fcn:
  hidden_size: 64
  num_layers: 7
  activation_function: "gelu"

# Data configuration
data_path: "data"

data:
  type: "mnist"  # Dataset type, e.g., "mnist", "cifar10", etc.